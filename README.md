<p align="center">
  <a href="https://github.com/destin-v"><img src="https://drive.google.com/uc?export=view&id=1yFte-RASCcF1ahkYg1Jybavi-gWje8kp" alt="drawing" width="500"/></a>
</p>

<div align="center">

  <a href="https://www.linkedin.com/in/william-li1">                                      ![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)</a>
  <a href="https://drive.google.com/drive/folders/1Ikf5t2HPSqViAnzc1mBZyH-V4iXWZSn3">     ![GoogleDrive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)</a>
  <a href="https://paypal.me/WilliamLi60?country.x=US&locale.x=en_US">                    ![Donate](https://img.shields.io/badge/Buy%20Me%20Coffee-lavender?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)</a>

</div>

# ✨ Description
🌱 I am a researcher working on projects that interest me.

🌱 I have worked for academic institutions as well as start-ups.

🌱 Have fun checking out my repos.

---
# 📚 Skills
| General                                                                 | Coding                                              | Software                                                        | Misc                                                         |
| :---------------------------------------------------------------------- | :-------------------------------------------------- | :-------------------------------------------------------------- | :----------------------------------------------------------- |
| ![badge](https://badgen.net/static/Reinforcement%20Learning/★★★★/green) | ![badge](https://badgen.net/static/Python/★★★★)     | ![badge](https://badgen.net/static/VSCode/★★★★/red)             | ![badge](https://badgen.net/static/AWS/★★☆☆/cyan)            |
| ![badge](https://badgen.net/static/Machine%20Learning/★★★☆/green)       | ![badge](https://badgen.net/static/MATLAB/★★★☆)     | ![badge](https://badgen.net/static/Microsoft%20Office/★★★★/red) | ![badge](https://badgen.net/static/SLURM/★★☆☆/cyan)          |
| ![badge](https://badgen.net/static/Bayesian%20Probability/★★★☆/green)   | ![badge](https://badgen.net/static/Ray/★★★☆)        | ![badge](https://badgen.net/static/Final%20Cut%20Pro/★★★☆/red)  |                                                              |
| ![badge](https://badgen.net/static/Kalman%20Filters/★★★☆/green)         | ![badge](https://badgen.net/static/PyTorch/★★☆☆)    | ![badge](https://badgen.net/static/JIRA/★☆☆☆/red)               | ![badge](https://badgen.net/static/Docker/★★☆☆/cyan)         |
| ![badge](https://badgen.net/static/Mathematics/★★★☆/green)              | ![badge](https://badgen.net/static/Tensorflow/★★☆☆) |                                                                 | ![badge](https://badgen.net/static/Apptainer/★★☆☆/cyan)      |
| ![badge](https://badgen.net/static/Computer%20Science/★★☆☆/green)       | ![badge](https://badgen.net/static/LaTeX/★★☆☆)      | ![badge](https://badgen.net/static/Mac%20OS/★★★★/red)           | ![badge](https://badgen.net/static/Kubernetes/★☆☆☆/cyan)     |
| ![badge](https://badgen.net/static/Cinematography/★★☆☆/green)           | ![badge](https://badgen.net/static/Git/★★☆☆)        | ![badge](https://badgen.net/static/Linux%20OS/★★★☆/red)         |                                                              |
| ![badge](https://badgen.net/static/Economics/★★☆☆/green)                | ![badge](https://badgen.net/static/Bash/★☆☆☆)       | ![badge](https://badgen.net/static/Windows%20OS/★☆☆☆/red)       | ![badge](https://badgen.net/static/Raspberry%20Pi/★★☆☆/cyan) |

# Select Papers

* **Li, W.**, Tatusko, J. “Model Zero - Reinforcement Learning for Policy Transfer into High-Fidelity Environments,” Small Business Innovation Research (SBIR). (2021) [**Video**](https://youtu.be/UMNB7BvNFEE?t=15309)

* Gardner, R. W., Richardson, C., Lowman, C. Llorens, A. J., Newman, A., Jamgochian A., Markowitz, J., Drenkow, N., **Li, W.**, Neller, T. W., Arora, R., Li, B., Kochenderfer, M. J., Lee, R. “Reconnaissance Blind Chess: A Challenge for Making Optimal Decision Under Uncertainty,” Neural Information Processing Systems. (2019) [**Link**](https://rbc.jhuapl.edu/) / [**Video**](https://slideslive.com/38923177/reconnaissance-blind-chess-competition)

* **Li, W.**, Richardson, C., Gardner R. “Reconnaissance Chess: Reinforcement Learning Exploration.” Johns Hopkins University Applied Physics Laboratory. (2018) [**Link**](https://drive.google.com/file/d/1TDix24pgtkuxHP5bmJ0f3DxNsUhn9t6v/view?usp=sharing)

* **Li, W.**, “Reconnaissance Blind Multi-Chess: Petrosian Algorithm.” Johns Hopkins University Applied Physics Laboratory. (2017) [**Link**](https://drive.google.com/file/d/1kkg_65ykMtjbMPKZrFET-JNhcIh2SP14/view?usp=sharing)
