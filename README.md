<p align="center">
  <a href="https://github.com/destin-v"><img src="https://drive.google.com/uc?export=view&id=1yFte-RASCcF1ahkYg1Jybavi-gWje8kp" alt="drawing" width="500"/></a>
</p>

<div align="center">

  <a href="https://www.linkedin.com/in/william-li1">                                      ![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)</a>
  <a href="https://drive.google.com/drive/folders/1Ikf5t2HPSqViAnzc1mBZyH-V4iXWZSn3">     ![GoogleDrive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)</a>
  <a href="https://paypal.me/WilliamLi60?country.x=US&locale.x=en_US">                    ![Donate](https://img.shields.io/badge/Buy%20Me%20Coffee-lavender?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)</a>

</div>

# âœ¨ Description
ğŸŒ± I am a researcher working on projects that interest me.

ğŸŒ± I have worked for academic institutions as well as start-ups.

ğŸŒ± Have fun checking out my repos.

---
# ğŸ“š Skills
| General                                                                 | Coding                                              | Software                                                        | Misc                                                         |
| :---------------------------------------------------------------------- | :-------------------------------------------------- | :-------------------------------------------------------------- | :----------------------------------------------------------- |
| ![badge](https://badgen.net/static/Reinforcement%20Learning/â˜…â˜…â˜…â˜…/green) | ![badge](https://badgen.net/static/Python/â˜…â˜…â˜…â˜…)     | ![badge](https://badgen.net/static/VSCode/â˜…â˜…â˜…â˜…/red)             | ![badge](https://badgen.net/static/AWS/â˜…â˜…â˜†â˜†/cyan)            |
| ![badge](https://badgen.net/static/Machine%20Learning/â˜…â˜…â˜…â˜†/green)       | ![badge](https://badgen.net/static/MATLAB/â˜…â˜…â˜…â˜†)     | ![badge](https://badgen.net/static/Microsoft%20Office/â˜…â˜…â˜…â˜…/red) | ![badge](https://badgen.net/static/SLURM/â˜…â˜…â˜†â˜†/cyan)          |
| ![badge](https://badgen.net/static/Bayesian%20Probability/â˜…â˜…â˜…â˜†/green)   | ![badge](https://badgen.net/static/Ray/â˜…â˜…â˜…â˜†)        | ![badge](https://badgen.net/static/Final%20Cut%20Pro/â˜…â˜…â˜…â˜†/red)  |                                                              |
| ![badge](https://badgen.net/static/Kalman%20Filters/â˜…â˜…â˜…â˜†/green)         | ![badge](https://badgen.net/static/PyTorch/â˜…â˜…â˜†â˜†)    | ![badge](https://badgen.net/static/JIRA/â˜…â˜†â˜†â˜†/red)               | ![badge](https://badgen.net/static/Docker/â˜…â˜…â˜†â˜†/cyan)         |
| ![badge](https://badgen.net/static/Mathematics/â˜…â˜…â˜…â˜†/green)              | ![badge](https://badgen.net/static/Tensorflow/â˜…â˜…â˜†â˜†) |                                                                 | ![badge](https://badgen.net/static/Apptainer/â˜…â˜…â˜†â˜†/cyan)      |
| ![badge](https://badgen.net/static/Computer%20Science/â˜…â˜…â˜†â˜†/green)       | ![badge](https://badgen.net/static/LaTeX/â˜…â˜…â˜†â˜†)      | ![badge](https://badgen.net/static/Mac%20OS/â˜…â˜…â˜…â˜…/red)           | ![badge](https://badgen.net/static/Kubernetes/â˜…â˜†â˜†â˜†/cyan)     |
| ![badge](https://badgen.net/static/Cinematography/â˜…â˜…â˜†â˜†/green)           | ![badge](https://badgen.net/static/Git/â˜…â˜…â˜†â˜†)        | ![badge](https://badgen.net/static/Linux%20OS/â˜…â˜…â˜…â˜†/red)         |                                                              |
| ![badge](https://badgen.net/static/Economics/â˜…â˜…â˜†â˜†/green)                | ![badge](https://badgen.net/static/Bash/â˜…â˜†â˜†â˜†)       | ![badge](https://badgen.net/static/Windows%20OS/â˜…â˜†â˜†â˜†/red)       | ![badge](https://badgen.net/static/Raspberry%20Pi/â˜…â˜…â˜†â˜†/cyan) |

# Select Papers

* **Li, W.**, Tatusko, J. â€œModel Zero - Reinforcement Learning for Policy Transfer into High-Fidelity Environments,â€ Small Business Innovation Research (SBIR). (2021) [**Video**](https://youtu.be/UMNB7BvNFEE?t=15309)

* Gardner, R. W., Richardson, C., Lowman, C. Llorens, A. J., Newman, A., Jamgochian A., Markowitz, J., Drenkow, N., **Li, W.**, Neller, T. W., Arora, R., Li, B., Kochenderfer, M. J., Lee, R. â€œReconnaissance Blind Chess: A Challenge for Making Optimal Decision Under Uncertainty,â€ Neural Information Processing Systems. (2019) [**Link**](https://rbc.jhuapl.edu/) / [**Video**](https://slideslive.com/38923177/reconnaissance-blind-chess-competition)

* **Li, W.**, Richardson, C., Gardner R. â€œReconnaissance Chess: Reinforcement Learning Exploration.â€ Johns Hopkins University Applied Physics Laboratory. (2018) [**Link**](https://drive.google.com/file/d/1TDix24pgtkuxHP5bmJ0f3DxNsUhn9t6v/view?usp=sharing)

* **Li, W.**, â€œReconnaissance Blind Multi-Chess: Petrosian Algorithm.â€ Johns Hopkins University Applied Physics Laboratory. (2017) [**Link**](https://drive.google.com/file/d/1kkg_65ykMtjbMPKZrFET-JNhcIh2SP14/view?usp=sharing)
